image_root: 'nocaps3'
ann_root: 'annotation'

# set pretrained as a file path or an url
pretrained: 'output/Caption_vitl/checkpoint_best.pth'
#pretrained: 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_caption_capfilt_large.pth'

vit: 'base'
batch_size: 1

image_size: 384

max_length: 20
min_length: 5
num_beams: 3
do_sample: ture
top_p: 0.9
prompt: 'a leaf of '
